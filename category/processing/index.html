
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../mlops/">
      
      
        <link rel="next" href="../documentation/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.0">
    
    
      
        <title>Processing - ssawadogo-blog</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.45e1311d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#processing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ssawadogo-blog" class="md-header__button md-logo" aria-label="ssawadogo-blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ssawadogo-blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Processing
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="amber"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ssawadogo-blog" class="md-nav__button md-logo" aria-label="ssawadogo-blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ssawadogo-blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Personal blog
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../cicd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CI/CD
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cloud
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../iagen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IAgen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../mlops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MlOps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
      
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Processing
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    documentation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="processing">Processing<a class="headerlink" href="#processing" title="Permanent link">&para;</a></h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/96554481?s=96&v=4" alt="Salif SAWADOGO">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-09-28 00:00:00">September 28, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">Processing</a></li>
        
        
          
          <li class="md-meta__item">
            
              8 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="faites-du-dask-plutot-que-du-spark-si-vous-avez-juste-de-grosses-tables-de-donnees"><a class="toclink" href="../../2024/09/28/faites-du-dask-plut%C3%B4t-que-du-spark-si-vous-avez-juste-de-grosses-tables-de-donn%C3%A9es/">Faites du Dask plutôt que du Spark si vous avez juste de grosses tables de données</a></h2>
<p>Dans le monde actuel des données, traiter de grands volumes nécessite des solutions performantes et évolutives. Le calcul distribué permet de gérer efficacement ces données en les répartissant sur plusieurs machines/cores/workers (selon votre cas). Cependant, toutes les entreprises n'ont pas besoin d'une infrastructure lourde et coûteuse telle qu'un cluster Spark. <strong>Dask</strong>, un framework Python, est une alternative légère et flexible, particulièrement adaptée aux environnements déjà basés sur Python.</p>

    <nav class="md-post__action">
      <a href="../../2024/09/28/faites-du-dask-plut%C3%B4t-que-du-spark-si-vous-avez-juste-de-grosses-tables-de-donn%C3%A9es/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/96554481?s=96&v=4" alt="Salif SAWADOGO">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-09-28 00:00:00">September 28, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">Processing</a></li>
        
        
          
          <li class="md-meta__item">
            
              15 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="encodage-efficace-des-variables-categorielles-pour-du-ml"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/">Encodage efficace des variables catégorielles pour du ML</a></h2>
<p>Les variables catégorielles, vous savez, elles sont omniprésentes dans nos ensembles de données, mais souvent, elles ne peuvent pas être utilisées telles quelles dans les algorithmes d'apprentissage automatique qui exigent des données numériques. Dans ce billet, nous allons explorer plusieurs techniques d'encodage pour transformer ces variables, le tout agrémenté d'explications claires, de formulations mathématiques, et quelques exemples pratiques. Nous aborderons aussi les avantages et les limites de chaque technique, que ce soit les "Classic Encoders", le "Contrast Encoder", ou les "Bayesian Encoders".</p>
<h3 id="exigences"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#exigences">Exigences</a></h3>
<p>Il faudra avoir <strong>pandas</strong> sous la main, et n'oubliez pas <strong>scikit-learn</strong> ainsi que <strong>category_encoders</strong>.</p>
<h3 id="donnees"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#donnees">Données</a></h3>
<p>Pour cet article, nous utiliserons le sous-ensemble de données ci-dessous :</p>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>B</td>
<td>0</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>A</td>
<td>1</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>A</td>
<td>0</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>C</td>
<td>1</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>A</td>
<td>0</td>
</tr>
<tr>
<td>6.0</td>
<td>2.9</td>
<td>4.5</td>
<td>B</td>
<td>0</td>
</tr>
<tr>
<td>6.5</td>
<td>3.0</td>
<td>5.8</td>
<td>C</td>
<td>1</td>
</tr>
<tr>
<td>5.3</td>
<td>3.7</td>
<td>1.5</td>
<td>A</td>
<td>0</td>
</tr>
<tr>
<td>7.1</td>
<td>3.0</td>
<td>5.9</td>
<td>B</td>
<td>0</td>
</tr>
<tr>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>C</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Pour modéliser cette table de données, il nous faut transformer la colonne x4 en variable numérique. En gros, nous allons discuter des différentes approches qui s'offrent à nous.</p>
<h3 id="classic-encoders"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#classic-encoders">Classic Encoders</a></h3>
<h4 id="1-label-encoding"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#1-label-encoding">1. Label Encoding</a></h4>
<h5 id="description"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description">Description</a></h5>
<p>L'encodage par étiquette attribue un entier unique à chaque catégorie d'une variable catégorielle. Cependant, attention ! Cette méthode peut insuffler une notion d'ordre qui pourrait être inappropriée pour des données purement nominales.</p>
<h5 id="expression-mathematique"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#expression-mathematique">Expression Mathématique</a></h5>
<p>Pour des catégories $ C_1, C_2, \ldots, C_n $, l'encodage se fait comme suit :
$$
\text{Valeur Encodée} = \text{index}(C_i) \quad \text{pour} \; i = 1, 2, \ldots, n
$$
où $ \text{index}(C_i) $ représente un entier unique associé à chaque catégorie.</p>
<h5 id="pratiquement"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement">Pratiquement</a></h5>
<p>Voici un petit extrait de code :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="n">data</span><span class="p">[</span><span class="s2">&quot;x4_LabelEncoder&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;x4&quot;</span><span class="p">])</span>
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
<th>x4_LabelEncoder</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>B</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>A</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>A</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>C</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>A</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>N’oublions pas l’inconvénient : cela peut introduire des valeurs qui n’ont pas de sens statistique.</p>
<h4 id="2-ordinal-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#2-ordinal-encoder">2. Ordinal Encoder</a></h4>
<h5 id="description_1"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_1">Description</a></h5>
<p>Il arrive que certaines catégories aient un sens d'ordre. Dans ce cas, un Label Encoder ne sera pas très utile et pourrait même causer des dommages dans les données. L'encodage ordinal attribue aussi un entier unique à chaque catégorie, mais cela se fait lorsque les catégories ont un ordre naturel. Pensez à des catégories telles que faible, moyen, et élevé ; cet ordre doit être respecté.</p>
<h5 id="expression-mathematique_1"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#expression-mathematique_1">Expression Mathématique</a></h5>
<p>Pour des catégories ordonnées $ C_1, C_2, \ldots, C_n $ où l'ordre naturel est $ C_1 &lt; C_2 &lt; \ldots &lt; C_n $, l'encodage ordinal se fait par : 
$$ 
\text{Valeur Encodée} = \text{position}(C_i) \quad \text{pour} \; i = 1, 2, \ldots, n 
$$ </p>
<p>où : 
- $ \text{position}(C_i) $ représente la position ordinale de la catégorie $ C_i $ dans l'ordre naturel. Si $ C_1 $ est la première, alors $ \text{position}(C_1) = 1 $ et ainsi de suite.</p>
<h5 id="pratiquement_1"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_1">Pratiquement</a></h5>
<p>Pour une variable catégorielle x4 représentant "Niveau de risque", avec les catégories suivantes : 
- C → Faible 
- B → Moyen 
- A → Élevé </p>
<p>Si l'ordre naturel est <em>Faible &lt; Moyen &lt; Élevé</em>, alors l'encodage ordinal sera : 
- <em>C</em> → 0 
- <em>B</em> → 1 
- <em>A</em> → 2</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="p">[[</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">]])</span>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="n">data</span><span class="p">[</span><span class="s2">&quot;x4_OrdinalEncoder&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s2">&quot;x4&quot;</span><span class="p">]])</span>
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
<th>x4_OrdinalEncoder</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>B</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>A</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>A</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>C</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>A</td>
<td>0</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>Cette méthode préserve l'ordre des catégories, crucial pour certaines analyses statistiques. En revanche, il faut s'assurer que cet ordre est bien défini dans le code <code>OrdinalEncoder(categories=[['C', 'B', 'A']])</code>.</p>
<h4 id="3-one-hot-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#3-one-hot-encoder">3. One-Hot Encoder</a></h4>
<h5 id="description_2"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_2">Description</a></h5>
<p>Ce procédé crée des colonnes binaires, ou indicatrices, pour chaque catégorie. Pour chaque observation, la colonne correspondant à la catégorie présente prend la valeur 1, et les autres sont à 0.</p>
<h5 id="mathematiquement"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#mathematiquement">Mathématiquement</a></h5>
<p>Soit $ C = { C_1, C_2, ..., C_n } $ les catégories d'une variable. Une observation appartenant à $ C_i $ est représentée par :
$$
\mathbf{x} = [0, 0, \ldots, 1, \ldots, 0] \quad \text{où la position } i \text{ est à 1}
$$</p>
<h5 id="pratiquement_2"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_2">Pratiquement</a></h5>
<p>Il existe plusieurs outils, mais restons simples avec la méthode <code>get_dummies</code> de pandas, que je trouve bien pratique.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x4&quot;</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;x4_OneHotEncoder&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>y</th>
<th>x4_OneHotEncoder_A</th>
<th>x4_OneHotEncoder_B</th>
<th>x4_OneHotEncoder_C</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>On peut jouer avec pas mal de paramètres. Pour les modèles statistiques, on a souvent tendance à fixer <code>drop_first=True</code> afin d'éviter le problème de colinéarité parfaite. Vous l'avez vu, on a transformé la variable x4 en plusieurs nouvelles caractéristiques. Cela peut poser problème si on a un grand nombre de catégories, ce qui pourrait mener à des matrices creuses. Dans une situation de ML training, cela peut entraîner du surapprentissage. Parfois, une sélection de caractéristiques devient alors inévitable.</p>
<p>https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html</p>
<h4 id="autres-encodeurs"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#autres-encodeurs">Autres encodeurs</a></h4>
<p>Je vous encourage aussi à jeter un œil sur deux encodeurs intéressants :
- Hashing encoder (https://contrib.scikit-learn.org/category_encoders/hashing.html) 
- Count encoder  (https://contrib.scikit-learn.org/category_encoders/count.html)</p>
<h3 id="contrast-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#contrast-encoder">Contrast Encoder</a></h3>
<p>Les encodeurs de contraste transforment les variables catégorielles en format numérique en créant des codes de contraste qui permettent aux algorithmes d'interpréter efficacement les resultats des modèles de regression. Voici quelques méthodes courantes pour encoder les contrastes :</p>
<h4 id="1-sum-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#1-sum-encoder">1. Sum Encoder</a></h4>
<h5 id="description_3"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_3">Description</a></h5>
<p>Cette méthode encode les variables de manière à ce que la somme des vecteurs encodés soit égale à zéro, évitant ainsi la multicolinéarité. Dans un modèle One Hot Encoding, on doit supprimer une catégorie et la garder comme référence. Ainsi :
+ Dans ce modèle, l'intercept représente la moyenne de la condition de référence.
+ Les coefficients représentent les effets simples, c'est-à-dire la différence entre une condition particulière et la condition de référence.</p>
<p>Cela n'est pas toujours du goût des statisticiens ! Ils ont donc introduit l'encodage par somme. Dans les modèles de régression :
+ L'intercept représente la moyenne générale du target à travers toutes les conditions.
+ Les coefficients des catégories sont alors interprétés comme la variation de la moyenne du target pour chaque catégorie par rapport à cette moyenne générale.</p>
<h4 id="mathematiquement_1"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#mathematiquement_1">Mathématiquement</a></h4>
<p>Pour des catégories $ C = { C_1, C_2, \ldots, C_n } $, si nous choisissons $ C_k $ comme catégorie de référence, une observation appartenant à $ C_i $ (où $ i \neq k $) se représente par :</p>
<div class="arithmatex">\[
\mathbf{x} = \begin{bmatrix} 1 &amp; 0 &amp; \ldots &amp; -1 &amp; -1 \end{bmatrix}
\]</div>
<p>où les valeurs sont :
-  $ 1  $ pour la catégorie $ C_1 $ 
-  $ 1  $ pour la catégorie $ C_2 $ 
-  $ -1  $ pour la catégorie de référence $ C_k $ 
-  $ 0  $ pour les autres catégories.</p>
<h4 id="pratiquement_3"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_3">Pratiquement</a></h4>
<p>Pour appliquer l'encodage Sum avec Pandas, on pourrait le faire directement, mais je vous conseille d'utiliser le package category_encoders, notamment la classe <a href="https://contrib.scikit-learn.org/category_encoders/sum.html">SumEncoder</a>.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="kn">from</span> <span class="nn">category_encoders.sum_coding</span> <span class="kn">import</span> <span class="n">SumEncoder</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="n">SE_encoder</span> <span class="o">=</span> <span class="n">SumEncoder</span><span class="p">(</span><span class="n">drop_invariant</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="n">SE_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
|   x1 |   x2 |   x3 |   x4_0 |   x4_1 |   y |
|------|------|------|--------|--------|-----|
|  5.6 |  3.4 |  1.5 |    1.0 |    0.0 |   0 |
|  7.8 |  2.7 |  6.9 |    0.0 |    1.0 |   1 |
|  4.9 |  3.1 |  1.5 |    0.0 |    1.0 |   0 |
|  6.4 |  3.2 |  5.3 |   -1.0 |   -1.0 |   1 |
|  5.1 |  3.8 |  1.6 |    0.0 |    1.0 |   0 |</p>
<p>Première remarque : il n’y a pas de catégorie de référence, car par défaut, c’est la dernière par ordre alphabétique. On ne peut pas choisir la catégorie de référence directement ici, mais une fois que l’on a compris le principe, on peut s’en charger par nous-mêmes. Pour obtenir les coefficients de la catégorie de référence, il suffit de prendre -1 et -1 pour <code>x4_0</code> et <code>x4_1</code>.</p>
<h4 id="2-helmert-coding"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#2-helmert-coding">2. Helmert Coding</a></h4>
<p>Pour plus de détails, consultez ce <a href="https://contrib.scikit-learn.org/category_encoders/helmert.html">lien</a>.</p>
<h3 id="bayesian-target-encoders"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#bayesian-target-encoders">Bayesian Target Encoders</a></h3>
<p>Les methodes classées comme Bayesiennes  sont des  technique utile pour encoder les variables catégorielles en tenant compte de la distribution du target. Cette approche intègre des informations a priori sur la variable cible, ce qui la rend particulièrement efficace pour améliorer la performance des modèles d'apprentissage automatique. Voici un aperçu :</p>
<h4 id="caracteristiques-cles"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#caracteristiques-cles">Caractéristiques clés:</a></h4>
<ol>
<li>
<p><strong>Cadre Bayésien</strong> : Cette méthode recourt à l’approche bayésienne pour estimer la moyenne du target pour chaque catégorie tout en considérant les informations provenant de l'ensemble de données global. Cela aide à atténuer les soucis liés au surajustement, surtout quand les catégories ont peu d'observations.</p>
</li>
<li>
<p><strong>Réduction (Shrinkage)</strong> : L'encodage cible bayésien applique une technique de réduction, où la moyenne de la catégorie est ajustée vers la moyenne générale du target, rendant l'encoding plus robuste.</p>
</li>
<li>
<p><strong>Gestion des Données Manquantes</strong> : Cette méthode s’accommode bien des données manquantes dans la caractéristique catégorique en fournissant une estimation significative basée sur les données accessibles.</p>
</li>
<li>
<p><strong>Cas d'Utilisation</strong> : L'encoding cible bayésien est particulièrement préconisé pour les variables catégorielles à forte cardinalité, où l'encoding one-hot entraînerait trop de caractéristiques.</p>
</li>
</ol>
<h4 id="1-target-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#1-target-encoder">1. Target encoder</a></h4>
<p>Le target encoder est une technique de transformation de variables catégorielles fondée sur la variable cible, souvent utilisée dans les modèles de machine learning supervisé. L'idée est de remplacer chaque catégorie par une valeur calculée à partir de la moyenne du target, avec un mécanisme de lissage pour prévenir le surajustement.</p>
<h5 id="mathematiquement_2"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#mathematiquement_2">Mathématiquement</a></h5>
<p>Avant d’explorer les formules, voici quelques notations cruciales :</p>
<ul>
<li><strong>$ y $ et $ y^+ $</strong> : Le nombre total d'observations et le nombre total d'observations positives (où $ y = 1 $).</li>
<li><strong>$ x_i, y_i $</strong> : La valeur de la catégorie et du target pour l'observation $ i $.</li>
<li><strong>$ n $ et $ n^+ $</strong> : Le nombre d'observations et le nombre d'observations positives pour une valeur spécifique d'une colonne catégorielle.</li>
<li><strong>$ a $</strong> : Un hyperparamètre de régularisation.</li>
<li><strong>$ prior $</strong> : La valeur moyenne du target sur l'ensemble du dataset.</li>
</ul>
<ol>
<li>
<p><strong>Calcul du Paramètre de Lissage ($ s $)</strong></p>
<p>Le paramètre de lissage est utilisé pour équilibrer la contribution entre la moyenne générale (prior) et la moyenne par catégorie :
 $$
 s = \frac{1}{1 + \exp\left(-\frac{n - mdl}{a}\right)}
 $$</p>
<p>où :
 - $ mdl $ est la valeur minimale de données par feuille,
 - $ a $ est le paramètre de lissage, qui ajuste la régularisation.</p>
</li>
<li>
<p><strong>Calcul de la valeur encodée ($ \hat{x}^k $)</strong></p>
<p>La valeur encodée pour chaque catégorie $ k $ est donnée par :
 $$
 \hat{x}^k = prior \cdot (1 - s) + s \cdot \frac{n^+}{n}
 $$</p>
<p>où :
 - $ prior $ est la moyenne globale du target,
 - $ s $ est le paramètre de lissage calculé,
 - $ \frac{n^+}{n} $ est la moyenne des cibles positives pour la catégorie $ k $.</p>
</li>
</ol>
<h5 id="pratiquement_4"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_4">Pratiquement</a></h5>
<p>On utilisera encore le package category_encoders, avec les valeurs par défaut :
<img alt="alt text" src="/encoding_categorical_features_for_ML/target_encoder.PNG" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">TargetEncoder</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">TargetEncoder</span><span class="p">()</span>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th style="text-align: center;">x1</th>
<th style="text-align: center;">x2</th>
<th style="text-align: center;">x3</th>
<th style="text-align: center;">x4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">5.6</td>
<td style="text-align: center;">3.4</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.422767</td>
</tr>
<tr>
<td style="text-align: center;">7.8</td>
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">0.458005</td>
</tr>
<tr>
<td style="text-align: center;">4.9</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.458005</td>
</tr>
<tr>
<td style="text-align: center;">6.4</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">5.3</td>
<td style="text-align: center;">0.628721</td>
</tr>
<tr>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">0.458005</td>
</tr>
</tbody>
</table>
<h5 id="desavantages-et-avantages"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#desavantages-et-avantages">Désavantages et avantages</a></h5>
<p>L'encoding par cible a ses avantages, mais attention à un <strong>inconvénient majeur</strong> : le surajustement potentiel, surtout pour les catégories avec peu de données. Le mécanisme de régularisation aide, mais il faut bien affiner les hyperparamètres pour ne pas qu'il surapprenne les relations spécifiques aux catégories rares.</p>
<p>Pour les <strong>Avantages</strong> :
1. <strong>Capture la relation avec le target :</strong> Directement intégrée, permettant d'améliorer la performance.
2. <strong>Réduit la dimensionnalité :</strong> Évite une explosion de dimensions comparé à l'encoding one-hot.
3. <strong>Gère les catégories Rares :</strong> Le lissage minimise le risque de surajustement pour les valeurs peu fréquentes.
4. <strong>Facile à interpréter :</strong> Les valeurs encodées reflètent des probabilités moyennes pondérées, ce qui simplifie l'analyse.</p>
<h4 id="2-m-estimate-coding"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#2-m-estimate-coding">2. M-Estimate coding</a></h4>
<p>L'M-Estimate encoder est une version simplifiée du target encoder qui a un seul paramètre de lissage, ce qui facilite sa mise en place et son ajustement. Conçu pour estimer la probabilité d'appartenance à une catégorie en utilisant une moyenne pondérée.</p>
<h5 id="description_4"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_4">Description</a></h5>
<p>M-Estimate coding est une technique simplifiée qui utilise un seul paramètre de lissage, facilitant son adaptation. Il est destiné à estimer la probabilité d'appartenance à une catégorie en s'appuyant sur une moyenne pondérée.</p>
<h5 id="mathematiquement_3"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#mathematiquement_3">Mathématiquement</a></h5>
<p>La formule de  M-Estimate coding est :</p>
<div class="arithmatex">\[
\hat{x}^k = \frac{n^+ + \text{prior} \cdot m}{n + m}
\]</div>
<p>où :
- $ n^+ $ : nombre de valeurs positives pour la catégorie $ k $,
- $ n $ : nombre total d'observations pour la catégorie $ k $,
- <em>prior</em> : moyenne globale du target,
- $ m $ : paramètre de lissage.</p>
<h5 id="pratiquement_5"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_5">Pratiquement</a></h5>
<p>Voici comment on peut implémenter ce type d'encoding en Python :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">MEstimateEncoder</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">MEstimateEncoder</span><span class="p">()</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>0.125</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>0.300</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>0.300</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>1.125</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>0.300</td>
</tr>
</tbody>
</table>
<h5 id="avantages-et-inconvenients"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#avantages-et-inconvenients">Avantages et inconvénients</a></h5>
<p><strong>Avantages :</strong>
1. <strong>Simple et efficace :</strong> Un seul paramètre de lissage à ajuster.
2. <strong>Réduction du surajustement :</strong> Le paramètre $ m $ stabilise les valeurs, réduisant l'impact des catégories rares.
3. <strong>Performance élevée :</strong> Pratique à implémenter et efficace pour les cibles binaires et continues.</p>
<p><strong>Inconvénients :</strong>
1. <strong>Régularisation limitée :</strong> Moins flexible que target encoder classique.
2. <strong>Pas idéal pour les cibles catégorielles multiples :</strong> Pour les cibles à plusieurs classes, un wrapper polynomial est nécessaire, complexifiant la méthode.</p>
<h4 id="3-leave-one-out-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#3-leave-one-out-encoder">3. Leave-One-Out encoder</a></h4>
<p>L'<strong>Leave-One-Out encoder</strong> (LOO) est une autre méthode tirée de target encoder, mais avec une variation importante pour minimiser la fuite d'information.</p>
<h5 id="description_5"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_5">Description</a></h5>
<p>L'idée est de calculer la <strong>moyenne du target</strong> pour chaque catégorie, mais sans inclure l'observation actuelle. Cela aide à limiter la fuite d'information puisque la valeur cible de l'observation en cours n'est pas intégrée dans sa propre transformation.</p>
<h5 id="mathematiquement_4"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#mathematiquement_4">Mathématiquement</a></h5>
<ol>
<li>
<p><strong>Calcul de la moyenne du target en Excluant l'Observation Actuelle</strong>
   Pour chaque observation $ i $ appartenant à la catégorie $ k $, la moyenne est calculée sans l’observation en cours par :
   $$
   x^k_i = \frac{\sum_{j \neq i} (y_j \cdot (x_j == k)) - y_i}{\sum_{j \neq i} (x_j == k)}
   $$</p>
<p>En excluant $ y_i $, on évite que le modèle "voit" sa propre valeur cible, ce qui réduit le risque de surapprentissage.</p>
</li>
<li>
<p><strong>Encodage des Données de Test</strong>
   Pour les données de test, chaque catégorie est remplacée par la <strong>moyenne du target</strong> calculée sur l'ensemble des données d'entraînement :
   $$
   x^k = \frac{\sum y_j \cdot (x_j == k)}{\sum (x_j == k)}
   $$</p>
</li>
</ol>
<h4 id="pratiquement_6"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_6">Pratiquement</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">LeaveOneOutEncoder</span>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">LeaveOneOutEncoder</span><span class="p">()</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>0</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>0</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>0.33</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>1.5</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>0.33</td>
</tr>
</tbody>
</table>
<p>Décomposons le calcul pour chaque observation dans la colonne <code>x4</code> :</p>
<p>Nous allons expliquer les calculs.
1. <strong>Calculer lamoyenne du target pour chaque catégorie en excluant l'observation actuelle.</strong>
2. <strong>Remplacer la valeur de la catégorie par cette moyenne pour chaque observation.</strong></p>
<h5 id="observation-1-index-0-categorie-b"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#observation-1-index-0-categorie-b">Observation 1 (index 0, catégorie "B") :</a></h5>
<ul>
<li>On exclut la première observation et on calcule la moyenne des cibles <code>y</code> pour les autres occurrences :<ul>
<li>Cibles des autres "B" : [0, 0]
-moyenne du target : $ \frac{0 + 0}{2} = 0 $</li>
</ul>
</li>
</ul>
<h5 id="observation-2-index-1-categorie-a"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#observation-2-index-1-categorie-a">Observation 2 (index 1, catégorie "A") :</a></h5>
<ul>
<li>On exclut cette observation et on fait de même :<ul>
<li>Cibles des autres "A" : [0, 0, 0]</li>
<li>Moyenne : $ \frac{0 + 0 + 0}{3} = 0 $</li>
</ul>
</li>
</ul>
<h5 id="observation-3-index-2-categorie-a"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#observation-3-index-2-categorie-a">Observation 3 (index 2, catégorie "A") :</a></h5>
<ul>
<li>On exclut :<ul>
<li>Cibles des autres "A" : [1, 0, 0]</li>
<li>Moyenne : $ \frac{1 + 0 + 0}{3} = \frac{1}{3} \approx 0.33 $</li>
</ul>
</li>
</ul>
<h5 id="observation-4-index-3-categorie-c"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#observation-4-index-3-categorie-c">Observation 4 (index 3, catégorie "C") :</a></h5>
<ul>
<li>Similaires :<ul>
<li>Cibles des autres "C" : [1, 2]</li>
<li>Moyenne : $ \frac{1 + 2}{2} = 1.5 $</li>
</ul>
</li>
</ul>
<h5 id="observation-5-index-4-categorie-a"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#observation-5-index-4-categorie-a">Observation 5 (index 4, catégorie "A") :</a></h5>
<ul>
<li>On exclut :<ul>
<li>Cibles des autres "A" : [1, 0, 0]</li>
<li>Moyenne : $ \frac{1 + 0 + 0}{3} = \frac{1}{3} \approx 0.33 $</li>
</ul>
</li>
</ul>
<p>Chaque observation est maintenant encodée avec la moyenne des cibles des autres observations de la même catégorie.</p>
<h5 id="avantages-et-inconvenients_1"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#avantages-et-inconvenients_1">Avantages et Inconvénients</a></h5>
<ul>
<li><strong>Avantages :</strong><ul>
<li><strong>Réduction de la fuite d'information</strong> : Sa méthode minimise les risques de biais.</li>
<li><strong>Capture des relations complexes</strong> : Comme target encoder, utile pour des relations non linéaires.</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Inconvénients :</strong><ul>
<li><strong>Complexité</strong> : Peut être coûteux en calculs sur de grands ensembles de données.</li>
<li><strong>Variabilité</strong> : Peut introduire de la variance avec de petites catégories, nécessitant une régularisation supplémentaire.</li>
</ul>
</li>
</ul>
<hr />
<h3 id="5-james-stein-encoding"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#5-james-stein-encoding">5. James-Stein encoding</a></h3>
<h4 id="description_6"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#description_6">Description</a></h4>
<p>L'encoding James-Stein est un encodeur basé sur des cibles. Son idée fondatrice est d'estimer la moyenne du target pour une catégorie donnée $ k $ selon la formule suivante :</p>
<p>$$
JS_i = (1-B) \cdot \text{mean}(y_i) + B \cdot \text{mean}(y)
 $$</p>
<p>où : 
- $ JS_i $ est l’estimation pour la catégorie $ C_i $,
- $ \text{mean}(y_i) $ est la moyenne des valeurs cibles pour la catégorie $ C_i $,
- $ \text{mean}(y) $ est la moyenne générale des cibles,
- $ B $ est un poids calculé qui équilibre l’influence de la moyenne conditionnelle et de la moyenne globale.</p>
<p>Cela semble très sensé. Nous cherchons une estimation qui se situe entre la moyenne de l'échantillon (risquant d'être extrême) et la moyenne globale.</p>
<h5 id="problematique-du-poids-b"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#problematique-du-poids-b">Problématique du poids $ B $</a></h5>
<p>Le poids $ B $ est défini par :</p>
<p>$$
B = \frac{\text{var}(y_i)}{\text{var}(y_i) + \text{var}(y)}
 $$</p>
<p>On se demande quel devrait être ce poids. Si on accorde trop de poids à la moyenne conditionnelle, on risque le surajustement, tandis qu'en privilégiant la moyenne globale, on peut sous-ajuster. Une approche canonique en apprentissage machine serait de passer par une validation croisée. Cependant, Charles Stein a proposé une solution en forme fermée. L'idée : ajuster la qualité des estimations selon la variance.</p>
<h5 id="limitations-de-lestimateur-james-stein"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#limitations-de-lestimateur-james-stein">Limitations de l'estimateur James-Stein</a></h5>
<p>Cet estimateur est limité aux distributions normales, ce qui ne convient pas à toutes les tâches de classification. Ainsi, on retrouve :</p>
<p>$$
SE^2 = \frac{\text{var}(y)}{\text{count}(y)}
 $$</p>
<p>Un défi majeur est que nous ne connaissons pas $ \text{var}(y) $. Il nous faudra donc estimer ces variances. Voici quelques solutions :</p>
<ol>
<li>
<p><strong>Modèle Pooled</strong> : Si toutes les observations sont semblables et prennent un nombre commun d'observations pour chaque valeur.</p>
</li>
<li>
<p><strong>Modèle Indépendant</strong> : Si les comptes d'observation diffèrent, il est plus judicieux de remplacer les variances par des erreurs standard, pénalisant ainsi les petites observations :</p>
</li>
</ol>
<p>$$
SE^2 = \frac{\text{var}(y)}{\text{count}(y)}
 $$</p>
<h5 id="application-pour-la-classification-binaire"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#application-pour-la-classification-binaire">Application pour la classification binaire</a></h5>
<p>Cet estimateur a une limitation pratique dans les modèles de classification binaire, où les cibles ne sont que $ 0 $ ou $ 1 $. Pour l'appliquer, on doit convertir lamoyenne du target dans l'intervalle borné $ &lt;0,1&gt; $ en remplaçant $ \text{mean}(y) $ par le ratio des cotes logarithmique :</p>
<p>$$
\text{log-odds_ratio}<em _text_not="\text{not">i = \log\left(\frac{\text{mean}(y_i)}{\text{mean}(y</em>\right)
 $$} \, i})</p>
<p>Cela s'appelle <strong>modèle binaire</strong>. C’est délicat d'estimer les paramètres de ce modèle, et parfois cela échoue. Il est souvent plus judicieux de recourir à un <strong>modèle bêta</strong>, souvent plus stable malgré une précision légèrement inférieure.</p>
<h5 id="pratiquement_7"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_7">Pratiquement</a></h5>
<p>Pour utiliser l'encodeur James-Stein, allez-y avec la classe <code>JamesSteinEncoder</code> de <code>category_encoders</code> :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">JamesSteinEncoder</span>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">JamesSteinEncoder</span><span class="p">()</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th></th>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>0.000000</td>
</tr>
<tr>
<td>1</td>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>0.250000</td>
</tr>
<tr>
<td>2</td>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>0.250000</td>
</tr>
<tr>
<td>3</td>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>1.333333</td>
</tr>
<tr>
<td>4</td>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>0.250000</td>
</tr>
<tr>
<td>5</td>
<td>6.0</td>
<td>2.9</td>
<td>4.5</td>
<td>0.000000</td>
</tr>
<tr>
<td>6</td>
<td>6.5</td>
<td>3.0</td>
<td>5.8</td>
<td>1.333333</td>
</tr>
<tr>
<td>7</td>
<td>5.3</td>
<td>3.7</td>
<td>1.5</td>
<td>0.250000</td>
</tr>
<tr>
<td>8</td>
<td>7.1</td>
<td>3.0</td>
<td>5.9</td>
<td>0.000000</td>
</tr>
<tr>
<td>9</td>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.333333</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="4-catboost-encoding"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#4-catboost-encoding">4. CatBoost Encoding</a></h4>
<hr />
<p>Il s'agit  d'une méthode d'encodage basée sur la cible, développée à l'origine pour être utilisée avec l'algorithme CatBoost, mais qui est applicable à d'autres modèles. Cet encodeur utilise une méthode particulière pour éviter la fuite d'information tout en exploitant les relations entre les catégories et ld target y.</p>
<h4 id="principe-du-catboost-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#principe-du-catboost-encoder">Principe du CatBoost encoder</a></h4>
<p>L'idée principale est d'utiliser les informations du target de manière ordonnée. Plutôt que de déterminer la moyenne du target pour chaque catégorie sur l'ensemble des données (qui peut introduire des fuites), CatBoost effectue une mise à jour de l'encodage de manière <strong>séquentielle</strong>.</p>
<h4 id="etapes-du-catboost-encoder"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#etapes-du-catboost-encoder">Étapes du catBoost encoder</a></h4>
<ol>
<li>
<p><strong>Ordre des observations</strong></p>
<ul>
<li>L'algorithme parcourt les données de manière ordonnée.</li>
<li>L'encodage pour chaque observation est basé sur les informations des observations <strong>précédentes</strong> seulement, empêchant ainsi la valeur du target actuelle d'affecter son propre encodage.</li>
</ul>
</li>
<li>
<p><strong>Calcul progressif de la moyenne du target</strong></p>
<ul>
<li>Pour chaque observation $ i $ dans la catégorie $ k $, la moyenne du target est calculée avec les observations <strong>précédentes</strong>. La formule est :
 $$
 x^k_i = \frac{\sum_{j &lt; i} (y_j \cdot (x_j == k)) + \text{prior} \cdot \alpha}{\sum_{j &lt; i} (x_j == k) + \alpha}
 $$
 où :</li>
<li>$ x^k_i $ est la valeur encodée pour l'observation $ i $ de la catégorie $ k $,</li>
<li>$ y_j $ est la valeur cible pour l'observation $ j $,</li>
<li>$ \text{prior} $ est une valeur moyenne générale du target,</li>
<li>$ \alpha $ est un paramètre de lissage pour éviter les divisions par zéro.</li>
</ul>
</li>
<li>
<p><strong>Encodage des données de test</strong></p>
<ul>
<li>Pour les données de test, l'encodage est basé sur les moyennes calculées à partir des données d'entraînement, sans fuite d'information.</li>
</ul>
</li>
</ol>
<h4 id="pourquoi-catboost-encoder-est-il-efficace"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pourquoi-catboost-encoder-est-il-efficace">Pourquoi CatBoost Encoder est-il Efficace ?</a></h4>
<p>L'encodeur CatBoost réduit efficacement la fuite d'information grâce à sa méthode de calcul séquentiel. Voici quelques atouts :
- <strong>Séquentiel et Progressif</strong> : En n'utilisant que les observations précédentes, il évite que la valeur actuelle influence son encodage.
- <strong>Régularisation</strong> : L'ajout d'un terme de régularisation permet de contrôler la variance.</p>
<h5 id="pratiquement_8"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#pratiquement_8">Pratiquement</a></h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">CatBoostEncoder</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">CatBoostEncoder</span><span class="p">()</span>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.6</td>
<td>3.4</td>
<td>1.5</td>
<td>0.500000</td>
</tr>
<tr>
<td>7.8</td>
<td>2.7</td>
<td>6.9</td>
<td>0.500000</td>
</tr>
<tr>
<td>4.9</td>
<td>3.1</td>
<td>1.5</td>
<td>0.750000</td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>5.3</td>
<td>0.500000</td>
</tr>
<tr>
<td>5.1</td>
<td>3.8</td>
<td>1.6</td>
<td>0.500000</td>
</tr>
<tr>
<td>6.0</td>
<td>2.9</td>
<td>4.5</td>
<td>0.250000</td>
</tr>
<tr>
<td>6.5</td>
<td>3.0</td>
<td>5.8</td>
<td>0.750000</td>
</tr>
<tr>
<td>5.3</td>
<td>3.7</td>
<td>1.5</td>
<td>0.375000</td>
</tr>
<tr>
<td>7.1</td>
<td>3.0</td>
<td>5.9</td>
<td>0.166667</td>
</tr>
<tr>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>0.833333</td>
</tr>
</tbody>
</table>
<p>Et voilà ! Pour appliquer l'encodeur CatBoost à la variable catégorielle <code>x4</code>, nous avons vu le calcul étape par étape. </p>
<h3 id="conclusion"><a class="toclink" href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/#conclusion">Conclusion</a></h3>
<p>Le choix de la meilleure méthode dépendra de votre cas d'utilisation et de la cardinalité des catégories. Est-on à la recherche d'un modèle explicatif ou prédictif ?  Dans le billet de blog de la semaine prochaine, je vais essayer de mesurer les performances de ces méthodes avec un modèle simple et voir qui s’en sort le mieux.</p>
    <nav class="md-post__action">
      <a href="../../2024/09/28/encodage-efficace-des-variables-cat%C3%A9gorielles-pour-du-ml/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/96554481?s=96&v=4" alt="Salif SAWADOGO">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-09-21 00:00:00">September 21, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">Processing</a></li>
        
        
          
          <li class="md-meta__item">
            
              6 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="apache-arrow-pour-loptimisation-du-traitement-des-donnees"><a class="toclink" href="../../2024/09/21/apache-arrow-pour-loptimisation-du-traitement-des-donn%C3%A9es/">Apache Arrow pour l'optimisation du traitement des données</a></h2>
<p>La gestion des données en mémoire ressemble parfois à un tatonnement. Les  data engineers, scientists et analysts se retrouvent souvent à jongler entre différents formats de données, calculs intensifs et besoins de performance. Jusqu’à récemment, nous étions limités par des outils et formats conçus pour des volumes et des vitesses bien inférieurs à ceux d’aujourd'hui. C’est là qu’<strong>Apache Arrow</strong> entre en scène, tel un champion prêt à transformer ce marathon en un sprint maîtrisé.
Dans ce billet de blog, on ne va parler que de données. Comment python gère les dataframes en backend?</p>

    <nav class="md-post__action">
      <a href="../../2024/09/21/apache-arrow-pour-loptimisation-du-traitement-des-donn%C3%A9es/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright © @sawallesalfo August 2024
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/sawadogosalif" target="_blank" rel="noopener" title="My GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://x.com/sawallesalfo" target="_blank" rel="noopener" title="My Twitter" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://www.linkedin.com/in/alif-sawadogo-statistician" target="_blank" rel="noopener" title="My LinkedIn" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<salif.sawadogo.pro@gmail.com>" target="_blank" rel="noopener" title="send me an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16H64zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V128z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "content.tabs", "content.code.annotate", "search.suggest", "search.highlight", "search.share"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>